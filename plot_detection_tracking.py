# -*- coding: utf-8 -*-
"""plot_detection_tracking.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IENpzis1jiSJRAPzpBRqRgOyhjUd4DEJ
"""

import pandas as pd
import random
import numpy as np
import cv2

def color_tuple(n = 1000):
    i = 0
    color_tuples = []
    while i < n:

        r = random.randint(0, 255)
        g = random.randint(0, 255)
        b = random.randint(0, 255)
        color_tuples.append((r, g, b))

        i += 1

    return color_tuples


csv_file_name = "enhancer_scenario1_Video_YOLO9.csv"
video_name = "enhancer_scenario1_Video.mp4"
output_video_name = "enhancer_scenario1_Video_Traj9.mp4"

# frame_num_to_draw = 72000

df_detections = pd.read_csv(csv_file_name)

cap = cv2.VideoCapture(video_name)
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))

fps = cap.get(cv2.CAP_PROP_FPS)
print(fps)
out = cv2.VideoWriter(output_video_name, -1, 8, (frame_width,frame_height))

length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

success = True
num_frame = 0

color_tuples = color_tuple(n = 1000)

while(cap.isOpened()):

    success, frame = cap.read()

    if success:

        frame_detected = df_detections[df_detections['frame'] == num_frame]

        for index, row in frame_detected.iterrows():

            obj_id = row['id']

            ccolor_i = int(obj_id) % 1000
            color = color_tuples[ccolor_i]

#             print(obj_id)

            vehicle_track = df_detections[(df_detections['frame'] <= num_frame) & (df_detections['id'] == obj_id)]

            for index, row in vehicle_track.iterrows():

                if index + 1 < vehicle_track.shape[0]:

                    x, y, w, h  = row["bb_left"] , row["bb_top"], row["bb_width"], row["bb_height"]
                    current_center = (round(x + w/2), round(y + h/2))

                    next_row = vehicle_track.iloc[index+1]
                    x, y, w, h  = next_row["bb_left"] , next_row["bb_top"], next_row["bb_width"], next_row["bb_height"]
                    next_center = (round(x + w/2), round(y + h/2))

#                   print(current_center)
                    frame = cv2.line(frame, current_center, next_center, color, thickness=2)
#                   frame = cv2.circle(frame, (round(x + w/2), round(y + h/2)), radius=2, color = color, thickness=-1)

            vehicle_track = df_detections[(df_detections['frame'] == num_frame) & (df_detections['id'] == obj_id)]
#             print(vehicle_track[["x", "y", "w", "h"]].values.tolist())
            x, y, w, h  = vehicle_track[["bb_left", "bb_top", "bb_width", "bb_height"]].values.tolist()[0]
#             print(x, y, w, h)
            frame = cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            frame = cv2.putText(frame, f"id: {obj_id}", (x, y-3), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        out.write(frame)
        num_frame += 1

        print(num_frame)
        if num_frame >= 3000:
            break

        #cv2.imshow('frame',frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    else:
        break

cap.release()
out.release()
cv2.destroyAllWindows()

"""## Count the Traffic"""

north_bound_pt1 = np.array([144, 163])
north_bound_pt2 = np.array([223, 106])

south_bound_pt1 = np.array([163, 84])
south_bound_pt2 = np.array([84, 128])

south_vector = north_bound_pt2 - north_bound_pt1
north_vector = south_bound_pt2 - south_bound_pt1
print(south_vector, north_vector)

